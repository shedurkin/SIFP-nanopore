---
title: "05.01-G2-Library3-MinION-Dorado-recall-GPU"
author: "Kathleen Durkin"
date: "2025-10-29"
always_allow_html: true
output: 
  github_document:
    toc: true
    toc_depth: 3
    number_sections: true
    html_preview: true 
  bookdown::html_document2:
    theme: cosmo
    toc: true
    toc_float: true
    number_sections: true
    code_folding: show
    code_download: true
---

I've been trialing Dorado basecalling to get my raw pod5 files to basecalled, demultiplexed, trimmed, and aligned BAM files, However, this is very computationally intensive and is taking hours to process 50-200Mb of output using CPUs along. `Dorado` is, however, optemized to run on GPUs, which would significantly cut run time!

I'm going to try using a Hyak GPU to run Dorado basecalling, using [Sam's previous work](https://robertslab.github.io/sams-notebook/posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-6129_403_26-on-Mox-with-GPU-Node/index.html) and the [Dorado basecaller documentation](https://software-docs.nanoporetech.com/dorado/latest/basecaller/basecall_overview/) as reference. 

```{r setup, include=FALSE}
library(knitr)
library(tidytable)
library(tidyverse)
knitr::opts_chunk$set(
  echo = TRUE,         # Display code chunks
  eval = FALSE,        # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  comment = ""         # Prevents appending '##' to beginning of lines in code output
)
```


# Create a Bash variables file

This allows usage of Bash variables (e.g. paths to common directories) across R Markdown chunks.
```{r save-bash-variables-to-rvars-file, engine='bash', eval=TRUE}
{
echo "#### Assign Variables ####"
echo ""

echo "# Data directories"
echo 'export nanopore_dir=/gscratch/srlab/kdurkin1/SIFP-nanopore'
echo 'export output_dir_top=${nanopore_dir}/B-Group2/output/05.01-G2-Library3-MinION-Dorado-recall-GPU'
echo 'export data_dir_top=${nanopore_dir}/B-Group2/data/05.01-G2-Library3-MinION-Dorado-recall-GPU'
echo 'export raw_pod5_dir=${data_dir_top}/pod5_pass'
echo 'export raw_pod5_url1="https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group2_MinION/Group2_Library3_MK1B_sequencer/20250902_1444_MN47571_FBD42232_1580300f/pod5_pass/"'
echo 'export raw_pod5_url2="https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group2_MinION/Group2_Library3_MK1B_after_wash2/20250903_2102_MN47571_FBD42232_3fa04fa7/pod5_pass/"'
echo 'export genome_dir=${nanopore_dir}/data/GCA_965233905.1_jaEunKnig1.1/'

echo 'export samtools=/srlab/programs/samtools-1.20/samtools'


echo "# Set FastQ filename patterns"
echo "export pod5_pattern='*.pod5'"
echo ""

echo "# Set number of CPUs to use"
echo 'export threads=20'
echo ""

echo "# Input/output files"
echo 'export raw_checksums=checksums.md5'
echo 'export trimmed_checksums=trimmed_fastq_checksums.md5'
echo ""
} > .bashvars

cat .bashvars
```

# Raw reads
## Download raw pod5 files

Reads are downloaded from: 
https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group2_MinION/Group2_Library3_MK1B_sequencer/20250902_1444_MN47571_FBD42232_1580300f/pod5_pass/ and https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group2_MinION/Group2_Library3_MK1B_after_wash2/20250903_2102_MN47571_FBD42232_3fa04fa7/pod5_pass/

Note that there are two directories of data for the Group 4 Library 1 MinION runs. One contains the bulk of the run, the second is everything after wash 2 (run errored out during wash 2)

Note that this directory contains multiple subdirectories, each representing one barcode (specimen) and containing the pod5 files associated with that barcode

The `--cut-dirs 7` command cuts the preceding directory structure (i.e. `nightingales/P_evermanni/30-789513166/`) so that we just end up with the reads.

```{r download-raw-reads, engine='bash', eval=FALSE}
# Load bash variables into memory
source .bashvars

# pre-wash2
wget \
--directory-prefix ${raw_pod5_dir}/pre_wash2 \
--recursive \
--no-check-certificate \
--continue \
--cut-dirs 6 \
--no-host-directories \
--no-parent \
--quiet \
--accept ${pod5_pattern} ${raw_pod5_url1}

# post-wash2
wget \
--directory-prefix ${raw_pod5_dir}/post_wash2 \
--recursive \
--no-check-certificate \
--continue \
--cut-dirs 6 \
--no-host-directories \
--no-parent \
--quiet \
--accept ${pod5_pattern} ${raw_pod5_url2}
```

```{r check-raw-reads, engine='bash', eval=TRUE}
# Load bash variables into memory
source .bashvars

ls -lh "${raw_pod5_dir}"
```

## Verify raw read checksums
```{r verify-raw-read-checksums, engine='bash', eval=FALSE}
# Load bash variables into memory
source .bashvars

wget \
--directory-prefix ${raw_pod5_dir}/pre_wash2 \
--recursive \
--no-check-certificate \
--continue \
--cut-dirs 6 \
--no-host-directories \
--no-parent \
--quiet \
--accept 'checksums.md5' ${raw_pod5_url1}

cd "${raw_pod5_dir}/pre_wash2"

# Recursively verify checksums in all subdirectories
find $(pwd) -type d | while read -r DIR; do
    # Check if checksums.md5 exists in this directory
    if [[ -f "$DIR/checksums.md5" ]]; then
        echo "Verifying checksums in $DIR"
        (
            cd "$DIR" || exit 1
            md5sum -c checksums.md5
        )
        echo ""
    fi
done
```

I've taken the SLURM script Sam made to run Guppy using `ckpt` GPU resources and modified it to use the dorado basecaller (available on Klone in the contatiner `/gscratch/srlab/containers/srlab-R4.4-bioinformatics-container-3886a1c.sif`). The modified script is saved in this directory under the name `05.01_G2L3_MinION_Dorado.sh`.

To run the script, run the below command from Klone terminal:
```{r, engine='bash', eval=FALSE}
sbatch 05.01_G2L3_MinION_Dorado.sh
```

Job ID 30553071


# BAM processing

Separate out mapped reads, and separate by barcode
```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Alignment summary
$samtools flagstat -O tsv FBD42232_pass_recalled.bam > FBD42232_pass_recalled_summary.tsv
```

```{r, engine='bash', eval=TRUE}
source .bashvars
cd ${output_dir_top}
cat FBD42232_pass_recalled_summary.tsv
```

From the samtools `flagstat` summary we see a high alignment rate of primary reads (59.69%), which is good! The majority of reads confidently come from *Eunicea*. There are, however, a lot of "secondary" and "supplementary" reads. "Secondary" indicates secondary alignments, i.e. alternative mapping locations of the same read. "Supplementary" indicates supplementary alignments, or parts of a read that align *discontinuously* (possibly chimeric, split, large structural variants, etc.). The true number of reads present in my sample is just the *primary* alignments (total - secondary - supplementary = 8176941-4554123-226378 = 3,396,440 reads). This is a rather annoying artifact of Dorado using a multimapper under the hood, where a single read can be mapped to multiple possible loci (one primary and 0 or more secondary). For downstream work, we only want to be using the "real" reads, not duplicate records of secondary/supplementary alignments, so we need to filter those out of the BAM. We also need to sort them

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Remove unmapped reads (bit decimal 4), secondary alignments (bit decimal 256) and supplementary alignments (bit decimal 2048)
$samtools view -b -F 2308 FBD42232_pass_recalled.bam |\
$samtools sort -o FBD42232_pass_recalled_mapped.bam

# Separate by barcode
$samtools view -h FBD42232_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode24/' |\
$samtools view -b |\
$samtools sort -o FBD42232_pass_recalled_mapped_barcode24.bam

$samtools view -h FBD42232_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode25/' |\
$samtools view -b |\
$samtools sort -o FBD42232_pass_recalled_mapped_barcode25.bam

$samtools view -h FBD42232_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode26/' |\
$samtools view -b |\
$samtools sort -o FBD42232_pass_recalled_mapped_barcode26.bam
```

Index
```{r, engine='bash', eval=FALSE}
source .bashvars
cd ${output_dir_top}

$samtools index FBD42232_pass_recalled_mapped.bam
$samtools index FBD42232_pass_recalled_mapped_barcode24.bam
$samtools index FBD42232_pass_recalled_mapped_barcode25.bam
$samtools index FBD42232_pass_recalled_mapped_barcode26.bam

```


# Summary stats

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Alignment summary
$samtools flagstat -O tsv FBD42232_pass_recalled_mapped.bam > flagstat_summary_FBD42232_pass_recalled_mapped.tsv
```

```{r, engine='bash', eval=TRUE}
cat flagstat_summary_FBD42232_pass_recalled_mapped.tsv

echo ""

# Summarize by barcode
$samtools view FBD42232_pass_recalled_mapped.bam | \
awk '{for(i=12;i<=NF;i++) if($i ~ /^BC:Z:/) {print substr($i,6)}}' | \
sort | uniq -c | sort -nr
```

There's a large discrepancy among the barcodes. The barcodes 24, 25, and 26 have ~0.3M, ~1M and ~0.7M reads, respectively.

## modkit modification summaries

Summarize modifications
```{r, engine='bash', eval=FALSE}
source .bashvars

$modkit summary -n 100000 ${output_dir_top}/FBD42232_pass_recalled_mapped.bam
```

OR, if doing this from Klone, need to use conda (run from terminal)

```{r, engine='bash', eval=FALSE}
source .bashvars

conda create -n modkit_env -c bioconda -c conda-forge ont-modkit
conda activate modkit_env

modkit summary -n 100000 ${output_dir_top}/FBD42232_pass_recalled_mapped.bam
```

```{}
> sampling 100000 reads from BAM
> calculating threshold at 10(th) percentile
> calculated thresholds: A: 0.9160156 C: 0.8144531
# bases             A,C 
# total_reads_used  77406 
# count_reads_A     77406 
# count_reads_C     73926 
# pass_threshold_A  0.9160156 
# pass_threshold_C  0.8144531 
 base  code  pass_count  pass_frac    all_count  all_frac 
 C     -     587131      0.94087136   633431     0.91368586 
 C     h     5094        0.008163082  18623      0.02686255 
 C     m     31804       0.05096558   41216      0.059451584 
 A     -     7027720     0.99699146   7664798    0.9796049 
 A     a     21207       0.003008543  159579     0.020395106
```

We're primarily interested in the passed read stats (though comparing to the "all" read stats can be useful). Even though only reads that passed the Nanopore quality filter were included in the modkit summary, there is still additional filtering happening in the summary process. That's because Nanopore quality filtering is read-level, and the modkit quality filtering is base-level. 
In mapped, primary-alignment reads, we observe low/negligible 6mA (~0.3%), low/negligible 5hmCG (~0.8%), and moderately-low 5mCG (~5%).

Now let's check by barcode (individual)

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

$modkit summary -n 100000 --tsv FBD42232_pass_recalled_mapped_barcode24.bam > modkit_summary_FBD42232_barcode24.tsv

echo ""

$modkit summary -n 100000 --tsv FBD42232_pass_recalled_mapped_barcode25.bam > modkit_summary_FBD42232_barcode25.tsv

echo ""

$modkit summary -n 100000 --tsv FBD42232_pass_recalled_mapped_barcode26.bam > modkit_summary_FBD42232_barcode26.tsv
```

OR, again, use a conda environment

Barplot of above modkit summaries
```{r, eval=TRUE}

files <- c(
  "../output/05.01-G2-Library3-MinION-Dorado-recall-GPU/modkit_summary_FBD42232_barcode24.tsv",
  "../output/05.01-G2-Library3-MinION-Dorado-recall-GPU/modkit_summary_FBD42232_barcode25.tsv",
  "../output/05.01-G2-Library3-MinION-Dorado-recall-GPU/modkit_summary_FBD42232_barcode26.tsv"
)

# Assign sample names (in same order as files)
sample_names <- c("barcode24", "barcode25", "barcode26")

# parse summaries
parse_modkit_summary <- function(file, sample_name) {
  df <- read.table(file, sep = "\t", header = FALSE, stringsAsFactors = FALSE)
  
  # Extract values (use pattern matching on the first column)
  get_val <- function(pattern) {
    as.numeric(df$V2[grep(pattern, df$V1)])
  }
  
  tibble(
    Sample = sample_name,
    `5mC`  = get_val("^C_pass_frac_modified_m") * 100,
    `5hmC` = get_val("^C_pass_frac_modified_h") * 100,
    `6mA`  = get_val("^A_pass_frac_modified_a") * 100
  )
}

# combine and convert to long format (for ggplotting)
mod_data <- map2_dfr(files, sample_names, parse_modkit_summary)

mod_long <- mod_data %>%
  pivot_longer(cols = c(`5mC`, `5hmC`, `6mA`),
               names_to = "Modification",
               values_to = "Percent")

# plot
ggplot(mod_long, aes(x = Sample, y = Percent, fill = Modification)) +
  geom_bar(stat = "identity", width=0.5, position = position_dodge(width = 0.5)) +
  geom_text(aes(label = sprintf("%.1f", Percent)),     # format to one decimal place
            position = position_dodge(width = 0.5), 
            vjust = -0.5, size = 4) +                  # adjust spacing & text size
  labs(
    title = "Modified Base Composition per Sample (trimmed, mapped reads)",
    y = "% Modified Bases (Pass Fraction)",
    x = NULL
  )

```

## genome coverage summaries

```{r, engine='bash', eval=FALSE}
source .bashvars
cd ${output_dir_top}

# conda create -n myenv
conda activate mosdepth_env
conda config --add channels bioconda
conda config --add channels conda-forge
conda config --add channels defaults
conda install -c bioconda mosdepth
mosdepth --version

```
