---
title: "04.01-G4-Library2-MinION-Dorado-recall-GPU"
author: "Kathleen Durkin"
date: "2025-10-29"
always_allow_html: true
output: 
  github_document:
    toc: true
    toc_depth: 3
    number_sections: true
    html_preview: true 
  bookdown::html_document2:
    theme: cosmo
    toc: true
    toc_float: true
    number_sections: true
    code_folding: show
    code_download: true
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE,         # Display code chunks
  eval = FALSE,        # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  comment = ""         # Prevents appending '##' to beginning of lines in code output
)
```

I've been trialing Dorado basecalling to get my raw pod5 files to basecalled, demultiplexed, trimmed, and aligned BAM files, However, this is very computationally intensive and is taking hours to process 50-200Mb of output using CPUs along. `Dorado` is, however, optemized to run on GPUs, which would significantly cut run time!

I'm going to try using a Hyak GPU to run Dorado basecalling, using [Sam's previous work](https://robertslab.github.io/sams-notebook/posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-6129_403_26-on-Mox-with-GPU-Node/index.html) and the [Dorado basecaller documentation](https://software-docs.nanoporetech.com/dorado/latest/basecaller/basecall_overview/) as reference. 

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = TRUE,         # Display code chunks
  eval = FALSE,        # Evaluate code chunks
  warning = FALSE,     # Hide warnings
  message = FALSE,     # Hide messages
  comment = ""         # Prevents appending '##' to beginning of lines in code output
)
```


# Create a Bash variables file

This allows usage of Bash variables (e.g. paths to common directories) across R Markdown chunks.
```{r save-bash-variables-to-rvars-file, engine='bash', eval=TRUE}
{
echo "#### Assign Variables ####"
echo ""

echo "# Data directories"
echo 'export nanopore_dir=/gscratch/srlab/kdurkin1/SIFP-nanopore'
echo 'export output_dir_top=${nanopore_dir}/D-Group4/output/04.01-G4-Library2-MinION-Dorado-recall-GPU'
echo 'export data_dir_top=${nanopore_dir}/D-Group4/data/04.01-G4-Library2-MinION-Dorado-recall-GPU'
echo 'export raw_pod5_dir=${data_dir_top}/pod5_pass'
echo 'export raw_pod5_url="https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group4_MinION/Library2/20250909_1146_MN47571_FBD36396_e03e7ede/pod5_pass/"'
echo 'export genome_dir=${nanopore_dir}/data/GCA_965233905.1_jaEunKnig1.1/'

echo 'export samtools=/srlab/programs/samtools-1.20/samtools'


echo "# Set FastQ filename patterns"
echo "export pod5_pattern='*.pod5'"
echo ""

echo "# Set number of CPUs to use"
echo 'export threads=20'
echo ""

echo "# Input/output files"
echo 'export raw_checksums=checksums.md5'
echo 'export trimmed_checksums=trimmed_fastq_checksums.md5'
echo ""
} > .bashvars

cat .bashvars
```


# Raw reads
## Download raw pod5 files

Reads are downloaded from: 
https://gannet.fish.washington.edu/kdurkin1/SIFP_2025/Group4_MinION/Library2/20250909_1146_MN47571_FBD36396_e03e7ede/pod5_pass/

Note that this directory contains multiple subdirectories, each representing one barcode (specimen) and containing the pod5 files associated with that barcode

The `--cut-dirs 7` command cuts the preceding directory structure (i.e. `nightingales/P_evermanni/30-789513166/`) so that we just end up with the reads.

```{r download-raw-reads, engine='bash', eval=FALSE}
# Load bash variables into memory
source .bashvars

wget \
--directory-prefix ${raw_pod5_dir} \
--recursive \
--no-check-certificate \
--continue \
--cut-dirs 6 \
--no-host-directories \
--no-parent \
--quiet \
--accept ${pod5_pattern} ${raw_pod5_url}
```

```{r check-raw-reads, engine='bash', eval=TRUE}
# Load bash variables into memory
source .bashvars

ls -lh "${raw_pod5_dir}"
```

## Verify raw read checksums
```{r verify-raw-read-checksums, engine='bash', eval=FALSE}
# Load bash variables into memory
source .bashvars

wget \
--directory-prefix ${raw_pod5_dir} \
--recursive \
--no-check-certificate \
--continue \
--cut-dirs 6 \
--no-host-directories \
--no-parent \
--quiet \
--accept 'checksums.md5' ${raw_pod5_url}

cd "${raw_pod5_dir}"

# Recursively verify checksums in all subdirectories
find $(pwd) -type d | while read -r DIR; do
    # Check if checksums.md5 exists in this directory
    if [[ -f "$DIR/checksums.md5" ]]; then
        echo "Verifying checksums in $DIR"
        (
            cd "$DIR" || exit 1
            md5sum -c checksums.md5
        )
        echo ""
    fi
done
```

# SLURM script

I've taken the SLURM script Sam made to run Guppy using `ckpt` GPU resources and modified it to use the dorado basecaller (available on Klone in the contatiner `/gscratch/srlab/containers/srlab-R4.4-bioinformatics-container-3886a1c.sif`). The modified script is saved in this directory under the name `04.01_G4L2_MinION_Dorado.sh`.

To run the script, run the below command from Klone terminal:
```{bash}
sbatch 04.01_G4L2_MinION_Dorado.sh
```

Job ID 30550488

# BAM processing

Separate out mapped reads, and separate by barcode
```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Alignment summary
$samtools flagstat -O tsv FBD36396_pass_recalled.bam > FBD36396_pass_recalled_summary.tsv
```

```{r, engine='bash', eval=TRUE}
source .bashvars
cd ${output_dir_top}
cat FBD36396_pass_recalled_summary.tsv
```

From the samtools `flagstat` summary we see a high alignment rate of primary reads (51.78%), which is good! The majority of reads confidently come from *Eunicea*. There are, however, a lot of "secondary" and "supplementary" reads. "Secondary" indicates secondary alignments, i.e. alternative mapping locations of the same read. "Supplementary" indicates supplementary alignments, or parts of a read that align *discontinuously* (possibly chimeric, split, large structural variants, etc.). The true number of reads present in my sample is just the *primary* alignments (total - secondary - supplementary = 3941300-2103601-118870 = 1,718,829 reads). This is a rather annoying artifact of Dorado using a multimapper under the hood, where a single read can be mapped to multiple possible loci (one primary and 0 or more secondary). For downstream work, we only want to be using the "real" reads, not duplicate records of secondary/supplementary alignments, so we need to filter those out of the BAM. We also need to sort them

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Remove unmapped reads (bit decimal 4), secondary alignments (bit decimal 256) and supplementary alignments (bit decimal 2048)
$samtools view -b -F 2308 FBD36396_pass_recalled.bam |\
$samtools sort -o FBD36396_pass_recalled_mapped.bam

# Separate by barcode
$samtools view -h FBD36396_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode30/' |\
$samtools view -b |\
$samtools sort -o FBD36396_pass_recalled_mapped_barcode30.bam

$samtools view -h FBD36396_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode31/' |\
$samtools view -b |\
$samtools sort -o FBD36396_pass_recalled_mapped_barcode31.bam

$samtools view -h FBD36396_pass_recalled_mapped.bam |\
awk '/^@/ || /BC:Z:SQK-NBD114-96_barcode32/' |\
$samtools view -b |\
$samtools sort -o FBD36396_pass_recalled_mapped_barcode32.bam
```

Index
```{r, engine='bash', eval=FALSE}
source .bashvars
cd ${output_dir_top}

$samtools index FBD36396_pass_recalled_mapped.bam
$samtools index FBD36396_pass_recalled_mapped_barcode30.bam
$samtools index FBD36396_pass_recalled_mapped_barcode31.bam
$samtools index FBD36396_pass_recalled_mapped_barcode32.bam

```


# Summary stats

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

# Alignment summary
$samtools flagstat -O tsv FBD36396_pass_recalled_mapped.bam > flagstat_summary_FBD36396_pass_recalled_mapped.tsv
```

```{r, engine='bash', eval=TRUE}
source .bashvars
cd ${output_dir_top}

cat flagstat_summary_FBD36396_pass_recalled_mapped.tsv

echo ""

# Summarize by barcode
$samtools view FBD36396_pass_recalled_mapped.bam | \
awk '{for(i=12;i<=NF;i++) if($i ~ /^BC:Z:/) {print substr($i,6)}}' | \
sort | uniq -c | sort -nr
```

There's a discrepancy among the barcodes. The barcodes 30, 31, and 32 have ~0.1M, ~0.2M and ~0.5M reads, respectively.

## modkit modification summaries

Summarize modifications
```{r, engine='bash', eval=FALSE}
source .bashvars

$modkit summary -n 100000 ${output_dir_top}/FBD36396_pass_recalled_mapped.bam
```

OR, if doing this from Klone, need to use conda (run from terminal)

```{r, engine='bash', eval=FALSE}
source .bashvars
cd ${output_dir_top}

conda create -n modkit_env -c bioconda -c conda-forge ont-modkit
conda activate modkit_env

modkit summary -n 100000 --filter-threshold C:0.85 --filter-threshold A:0.95  FBD36396_pass_recalled_mapped.bam
```

```{}
> sampling 100000 reads from BAM
> calculating threshold at 10(th) percentile
> calculated thresholds: C: 0.671875 A: 0.7675781
# bases             A,C 
# total_reads_used  77139 
# count_reads_C     73936 
# count_reads_A     77139 
# pass_threshold_A  0.7675781 
# pass_threshold_C  0.671875 
 base  code  pass_count  pass_frac    all_count  all_frac 
 C     -     530967      0.91877586   561767     0.87576854 
 C     h     13887       0.024029817  33717      0.05256323 
 C     m     33053       0.057194322  45972      0.07166821 
 A     -     6552728     0.987465     7088277    0.9620367 
 A     a     83181       0.012534982  279713     0.03796327
```

We're primarily interested in the passed read stats (though comparing to the "all" read stats can be useful). Even though only reads that passed the Nanopore quality filter were included in the modkit summary, there is still additional filtering happening in the summary process. That's because Nanopore quality filtering is read-level, and the modkit quality filtering is base-level. 
In mapped, primary-alignment reads, we observe low 6mA (~1%), low 5hmCG (~2.5%), and moderately-low 5mCG (~6%). Notably, these are all higher than in G1L4 (the modern samples)

Now let's check by barcode (individual)

```{r, engine='bash', eval=FALSE}
source .bashvars

cd ${output_dir_top}

$modkit summary -n 100000 --tsv FBD36396_pass_recalled_mapped_barcode30.bam > modkit_summary_FBD36396_barcode30.tsv

echo ""

$modkit summary -n 100000 --tsv FBD36396_pass_recalled_mapped_barcode31.bam > modkit_summary_FBD36396_barcode31.tsv

echo ""

$modkit summary -n 100000 --tsv FBD36396_pass_recalled_mapped_barcode32.bam > modkit_summary_FBD36396_barcode32.tsv
```

OR, again, use a conda environment

Barplot of above modkit summaries
```{r, eval=TRUE}

files <- c(
  "../output/04.01-G4-Library2-MinION-Dorado-recall-GPU/modkit_summary_FBD36396_barcode30.tsv",
  "../output/04.01-G4-Library2-MinION-Dorado-recall-GPU/modkit_summary_FBD36396_barcode31.tsv",
  "../output/04.01-G4-Library2-MinION-Dorado-recall-GPU/modkit_summary_FBD36396_barcode32.tsv"
)

# Assign sample names (in same order as files)
sample_names <- c("barcode30", "barcode31", "barcode32")

# parse summaries
parse_modkit_summary <- function(file, sample_name) {
  df <- read.table(file, sep = "\t", header = FALSE, stringsAsFactors = FALSE)
  
  # Extract values (use pattern matching on the first column)
  get_val <- function(pattern) {
    as.numeric(df$V2[grep(pattern, df$V1)])
  }
  
  tibble(
    Sample = sample_name,
    `5mC`  = get_val("^C_pass_frac_modified_m") * 100,
    `5hmC` = get_val("^C_pass_frac_modified_h") * 100,
    `6mA`  = get_val("^A_pass_frac_modified_a") * 100
  )
}

# combine and convert to long format (for ggplotting)
mod_data <- map2_dfr(files, sample_names, parse_modkit_summary)

mod_long <- mod_data %>%
  pivot_longer(cols = c(`5mC`, `5hmC`, `6mA`),
               names_to = "Modification",
               values_to = "Percent")

# plot
ggplot(mod_long, aes(x = Sample, y = Percent, fill = Modification)) +
  geom_bar(stat = "identity", width=0.5, position = position_dodge(width = 0.5)) +
  geom_text(aes(label = sprintf("%.1f", Percent)),     # format to one decimal place
            position = position_dodge(width = 0.5), 
            vjust = -0.5, size = 4) +                  # adjust spacing & text size
  labs(
    title = "Modified Base Composition per Sample (trimmed, mapped reads)",
    y = "% Modified Bases (Pass Fraction)",
    x = NULL
  )

```

## genome coverage summaries

```{r, engine='bash', eval=FALSE}
source .bashvars
cd ${output_dir_top}

# conda create -n myenv
conda activate mosdepth_env
conda config --add channels bioconda
conda config --add channels conda-forge
conda config --add channels defaults
conda install -c bioconda mosdepth
mosdepth --version

```


